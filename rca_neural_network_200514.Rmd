---
title: "MLM Term Paper R Code"
author: "Wooyong Jung (wj710)"
date: "5/14/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, tidy=TRUE, message = FALSE, warning = FALSE)
```

```{r basic setting}
# Load libraries
library(haven)
library(ggplot2)
library(tidyverse)
library(keras)
library(tfruns)
```

```{r data cleansing for RCA}
# Load dataset
## RCA data
load("Termpaper/dataset/country_sitcproduct4digit_year.RData")
## SITC product and country(location) code
pid <- read_dta("Termpaper/dataset/sitc_product.dta")
loc <- read_dta("Termpaper/dataset/location.dta")

# Merge pid and loc into main data frame
df <- merge(table, pid[,-5], by="product_id", all.x = TRUE)
df <- merge(df, loc[,c(1,2,3,4)], by="location_id", all.x = TRUE)

# Select variables needed for this study
df <- df %>% 
  select(location_id, product_id, year, export_rca, sitc_product_name_short_en, location_code.x, location_name_short_en)

# Change column name
colnames(df) <- c("lid", "pid", "year", "rca", "product", "iso", "country")
```

```{r data cleansing for GDP growth}
# Load gdp growth
gdp <- read_csv("Termpaper/dataset/gdp_growth.csv")

# Convert to long data
gdp <- gather(gdp, year, growth, `1961`:`2018`)

# Check quantile level
quantile(gdp$growth, na.rm = TRUE)

# Create growth level variable (1 to 4)
gdp %>% 
  mutate(growth = ntile(growth, 4)) -> gdp

# Convert growth level 0 to 3
gdp <- gdp %>% 
  mutate(growth = ifelse(growth == 1, 0,
                           ifelse(growth == 2, 1,
                                  ifelse(growth == 3, 2,
                                         ifelse(growth == 4, 3, NA)))))

```

```{r data cleansing for TFP}
# Load Penn World Table data
pwt <- read_csv("Termpaper/dataset/penntable.csv")

# Choose variables needed
pwt <- pwt %>% 
  select(iso, country, year, ctfp)

# Convert to long data
pwt %>% 
  mutate(tfp = ntile(ctfp, 5)) -> pwt

# Check quantile level
quantile(pwt$ctfp, na.rm = TRUE)
pwt <- pwt[,-4]

# Convert TFP level 0 to 3
pwt <- pwt %>% 
  mutate(tfp = ifelse(tfp == 1, 0,
                           ifelse(tfp == 2, 1,
                                  ifelse(tfp == 3, 2,
                                         ifelse(tfp == 4, 3, NA)))))
```

```{r merge RCA, growth and TFP datasets}
# Merge growth into df and make new dataframe (df.growth)
df_growth <- merge(df, gdp, by = c("iso", "year"), all.x = TRUE)

# Remain only complete cases and select variables needed
df_growth <- df_growth %>% 
  drop_na() %>%
  select(iso, year, pid, rca, growth)

# Convert to wide format (products in column) and Change NA to 0
## NA means that the country has no RCA of the product
df_growth <- df_growth %>% 
  spread(pid, rca) %>% 
  mutate_at(vars(3:785), funs(ifelse(is.na(.), 0, .)))

# Convert RCA as a binary
df_growth <- df_growth %>% 
  mutate_at(vars(4:785), funs(ifelse(.>1, 1, 0)))

# Merge TFP into df and make new dataframe (df_tfp)
df_tfp <- merge(df, pwt, by = c("iso", "year"), all.x = TRUE)

# Remain only complete cases and select variables needed
df_tfp <- df_tfp %>% 
  drop_na() %>% 
  select(iso, year, pid, rca, tfp)

# Convert  to wide (products in column) and Change NA to 0
## NA means that the country has no RCA of the product
df_tfp <- df_tfp %>% 
  spread(pid, rca) %>% 
  mutate_at(vars(3:785), funs(ifelse(is.na(.), 0, .)))

# Convert RCA as a binary
df_tfp <- df_tfp %>% 
  mutate_at(vars(4:785), funs(ifelse(.>1, 1, 0)))
```

```{r MLP for predicting growth rate}
# Convert df.growth into a matrix
df_growth <- df_growth[,-c(1,2)]
mat_growth <- as.matrix(df_growth)
dimnames(mat_growth) <- NULL

# Seperate into train and test set
set.seed(123)
idx_growth <- sample(2, nrow(mat_growth), replace = TRUE, prob = c(0.8, 0.2))
growth_x_train <- mat_growth[idx_growth == 1, 2:783]
growth_x_test <- mat_growth[idx_growth == 2, 2:783]

growth_y_test_actual <- mat_growth[idx_growth == 2, 1]

growth_y_train <- to_categorical(mat_growth[idx_growth == 1, 1])
growth_y_test <- to_categorical(mat_growth[idx_growth == 2, 1])

cbind(growth_y_test_actual[1:10], growth_y_test[1:10,])
```

```{r Baseline model}
# Hyperparameter tuning
runs <- tuning_run("tuning1.R",
                   flags = list(dense_units1 = c(32, 64),
                                dense_units2 = c(32, 64),
                                dense_units3 = c(16, 32),
                                activation1 = c("relu", "sigmoid"),
                                activation2 = c("relu", "sigmoid"),
                                activation3 = c("relu", "sigmoid")))

# Create a baseline model
bm_growth <- keras_model_sequential()
bm_growth %>% 
  layer_dense(units = 64, activation = "relu", input_shape = 782) %>% 
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dense(units = 20, activation = "relu") %>% 
  layer_dense(units = 4, activation = "softmax") 
summary(bm_growth)

# Compile the model
bm_growth %>% 
  compile(loss = "categorical_crossentropy",
          optimizer = "adam",
          metrics = c("accuracy"))

# Fit the data
history <- bm_growth %>% 
  fit(growth_x_train, growth_y_train, epoch = 10, batch_size = 64, validation_split = 0.1, verbose = 2)

```


```{r L2 Regularization}
# Create a baseline model
l2_growth <- keras_model_sequential()
l2_growth %>% 
  layer_dense(units = 50, activation = "relu", input_shape = 782,
              kernel_regularizer = regularizer_l2(0.01)) %>% 
  layer_dense(units = 20, activation = "relu",
              kernel_regularizer = regularizer_l2(0.01)) %>% 
  layer_dense(units = 20, activation = "relu",
              kernel_regularizer = regularizer_l2(0.01)) %>% 
  layer_dense(units = 4, activation = "softmax") 
summary(l2_growth)

# Compile the model
l2_growth %>% 
  compile(loss = "categorical_crossentropy",
          optimizer = "adam",
          metrics = c("accuracy")) 

# Fit the data
history <- l2_growth %>% 
  fit(growth_x_train, growth_y_train, epoch = 10, batch_size = 64, validation_split = 0.1, verbose = 2)

```

```{r Dropout}
# Hyperparameter tuning
runs <- tuning_run("experiment.R",
                   flags = list(dense_units1 = c(32, 64),
                                dense_units2 = c(32, 64),
                                dropout1 = c(0.4, 0.6),
                                dropout2 = c(0.4, 0.6)))


# Create a dropout model
dp_growth <- keras_model_sequential()
dp_growth %>% 
  layer_dense(units = 64, activation = "relu", input_shape = 782) %>% 
  layer_dropout(0.5) %>%
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dropout(0.5) %>% 
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dropout(0.5) %>% 
  layer_dense(units = 4, activation = "softmax") 
summary(dp_growth)

# Compile the model
dp_growth %>% 
  compile(loss = "categorical_crossentropy",
          optimizer = "adam",
          metrics = c("accuracy"))

# Fit the data
history <- dp_growth %>% 
  fit(growth_x_train, growth_y_train, epoch = 10, batch_size = 64, validation_split = 0.1, verbose = 2)

```
